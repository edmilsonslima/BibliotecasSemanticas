# -*- coding: utf-8 -*-
"""Terminologiafinal1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13QYRWyV3Di3ZC20tEYAXddM2G6Lmey55
"""

!pip install pyspellchecker
!pip install chardet
!pip install beautifulsoup4
!pip install requests
!pip install autocorrect
!pip install textblob
!pip install language-tool-python

import requests
import textwrap
import chardet
from spellchecker import SpellChecker
from bs4 import BeautifulSoup

spell = SpellChecker()

# URL da página web
url = "http://www.portaldalinguaportuguesa.org/?action=terminology&query="

# Entrada do usuário
palavra = input("Digite a palavra para busca: ").strip()

# Lista para armazenar os dados extraídos
dados = []

# Construção da URL completa
url_completa = url + palavra
response = requests.get(url_completa)
response.encoding = 'utf-8'

# Verificar se a página foi acessada com sucesso
if response.status_code == 200:
    html = response.text
    soup = BeautifulSoup(html, "html.parser")

    # Titulo 1
    titulo1 = soup.find("h1")
    if titulo1:
        print()
        print(titulo1.get_text(strip=True))
    else:
        print("Titulo não encontrado.")

    # Titulo 2
    titulo2 = soup.find("h2")
    if titulo2:
        print(titulo2.get_text(strip=True))
        print()
    else:
        print("Titulo não encontrado.")

    # Busca pelos resultados
    resultado = soup.find_all("ul", style="margin-top: 0px; margin-bottom: 20px;")
    if resultado:
        ul_tag = soup.find("ul")
        if ul_tag:
            # Encontrar todas as tags <a> dentro de <ul>
            tags_a = ul_tag.find_all("a")
            textos = [tag.get_text(strip=True) for tag in tags_a]
            links = [tag['href'] for tag in tags_a]

            # Armazenar os textos e links no formato "texto - link"
            for texto, link in zip(textos, links):
                dados.append(f"{texto} - {link}")
                #print(f"{texto} - {link}")
        else:
            print("Nenhuma tag <ul> encontrada nos resultados.")
    else:
        print("Nenhum resultado encontrado.")
else:
    print(f"Erro ao acessar a página: {response.status_code}")

# Lista para armazenar os links correspondentes
links_da_palavra = []

# Iterando sobre os dados extraídos
for linha in dados:  # 'dados' agora é uma lista de strings no formato "texto - link"
    partes = linha.split(" - ")  # Divide cada linha em texto e link
    if len(partes) == 2:  # Garante que há exatamente um texto e um link
        texto, link = partes
        palavras_texto = texto.split()  # Divide o texto em palavras
        if palavra in palavras_texto:  # Verifica se a palavra está no texto
            links_da_palavra.append(link)  # Adiciona o link à lista


# recuperar a terminologia das palavras

# Iterando sobre cada elemento da lista dos links
for link in links_da_palavra:
  url1 = "http://www.portaldalinguaportuguesa.org/"
  url1 = url1+link
  url1 = url1+palavra
  response = requests.get(url1)
  response.encoding = 'utf-8'
  html = response.text

  soup = BeautifulSoup(html, "html.parser")
  Titulo11 = soup.find("h1").get_text()
  Titulo22 = soup.find("h2").get_text()
  classificacao = soup.find("table", cellpadding="5").get_text()
  definicao = soup.find("i").get_text()
  definicao = "Definições:"
  texto = soup.find("div", attrs={"style":"margin: 15px; padding: 10px; border: 1px solid #dedede; background-color: #eeeeee"}).get_text()
  print()
  print(Titulo11)
  print(Titulo22)
  print(classificacao)
  print(definicao)

  try:
    texto = texto.encode('latin1').decode('utf-8', errors='ignore')
  except UnicodeEncodeError:
    #print("Encoding error encountered. Skipping problematic character.")
    print()
  texto = " ".join(texto.split())
  texto_formatado = textwrap.fill(texto, width=80)
  #print(texto_formatado)
  correcoes = spell.correction(texto_formatado)
  print(correcoes)
  # Detectar a codificação original
  #detected = chardet.detect(texto_formatado.encode())
  #encoding_detected = detected['encoding']
  #confidence = detected['confidence']
  #print(f"Codificação detectada: {encoding_detected} (Confiança: {confidence * 100:.2f}%)")